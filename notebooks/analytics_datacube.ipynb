{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics DataCube\n",
    "\n",
    "> üëã Before moving on with this demo, you must first sign-up and request your Geosys APIs credentials here :\n",
    "> - ‚öôÔ∏è[Try it now](https://earthdailyagro.com/geosys-registration/)\n",
    "\n",
    "> For more information about our Geosys APIs : \n",
    "> - üìö [Geosys APIs to connect with your digital ag application](https://app.geosys.com/#/documentation)\n",
    "\n",
    "\n",
    "> **Demo Project:** This demo demonstrates the ability to create an Analytics Datacube of CLEAR images based on geosysPy.\n",
    "The generated output is a zarr file  available on the selected cloud storage provider. (AWS/Azure Blob Storage)\n",
    "\n",
    "\n",
    "\n",
    "### @author: Geosys\n",
    "\n",
    "\n",
    "\n",
    " ## 1Ô∏è‚É£ Import all librairies needed and get an autorization to use Analytics Datacube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join('..','src'))\n",
    "from geosyspy import Geosys\n",
    "from geosyspy.utils.constants import *\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from analytics_datacube.processor import AnalyticsDatacube\n",
    "from analytics_datacube.utils import dataset_to_zarr_format\n",
    "import datetime as dt\n",
    "import logging\n",
    "import xarray\n",
    "from cloud_storage import cloud_storage_aws,cloud_storage_azure\n",
    "\n",
    "logger = logging.getLogger()\n",
    "#logger.setLevel(logging.ERROR)\n",
    "logger.setLevel(logging.WARNING)\n",
    "\n",
    "# read .env file\n",
    "load_dotenv()\n",
    "\n",
    "API_CLIENT_ID = os.getenv('API_CLIENT_ID')\n",
    "API_CLIENT_SECRET = os.getenv('API_CLIENT_SECRET')\n",
    "API_USERNAME = os.getenv('API_USERNAME')\n",
    "API_PASSWORD = os.getenv('API_PASSWORD')\n",
    "\n",
    "\n",
    "# Create and initialize the client\n",
    "print(\"Initializing the client...\")\n",
    "client = AnalyticsDatacube(API_CLIENT_ID, API_CLIENT_SECRET, API_USERNAME, API_PASSWORD, Env.PROD, Region.NA)\n",
    "print(\"Client initialized !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2Ô∏è‚É£ Input data\n",
    "\n",
    "These input parameters are utilized in the demo to generate Analytics DataCube\n",
    "\n",
    "\n",
    "##### polygon: \n",
    "A polygon string in WKT or GeoJson format. This polygon defines the boundaries of the area under analysis.\n",
    "\n",
    "#### start_date: \n",
    "A datetime object representing the start date of generated DataCube.\n",
    "\n",
    "#### end_date: \n",
    "A datetime object representing the end date of generated  DataCube\n",
    "\n",
    "#### indicators: \n",
    "A string array representing index indicators on wich the analysis is made.\n",
    "Possible values for indicator are:\n",
    "- ndvi\n",
    "- evi\n",
    "- gndvi\n",
    "- ndwi\n",
    "- cvi\n",
    "- cvin\n",
    "- lai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WKT \n",
    "#polygon = \"POLYGON((-90.41 41.6663, -90.41 41.6545, -90.3775 41.6541, -90.3778 41.6660, -90.41 41.6663))\"\n",
    "polygon =\"POLYGON((-90.41169914 41.66631642, -90.41178502 41.6545818, -90.37753855 41.65413284, -90.37788188 41.666059940000004, -90.41169914 41.66631642))\"\n",
    "# GeoJson\n",
    "#polygon = '{\"type\": \"Polygon\",\"coordinates\": [[[-90.41, 41.6663],[-90.41, 41.6545],[-90.3775, 41.6541],[-90.3778, 41.666],[-90.41, 41.6663]]]}'\n",
    "\n",
    "endDate = dt.date.today()\n",
    "\n",
    "startDate = endDate + relativedelta(months=-12)\n",
    "\n",
    "indicators = [\"NDVI\", \"NDWI\", \"EVI\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Generate the analytics datacube\n",
    "Generate an analytics datacube compute on each index values by pixel over the defined period for the specified polygon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics_datacube = client.generate_analytics_datacube(polygon, startDate, endDate, indicators)\n",
    "analytics_datacube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Save the generated analytics DataCube in a Zarr file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as zarr\n",
    "zarr_path = dataset_to_zarr_format(analytics_datacube)\n",
    "zarr_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Upload result on Cloud Storage accounts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload on AWS Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloud_storage_aws.upload_folder_to_aws_s3(zarr_path):\n",
    "    print(\"Analytics DataCube uploaded to AWS\")\n",
    "    print(f'S3 uri: {cloud_storage_aws.get_s3_uri_path(zarr_path)}')\n",
    "else:\n",
    "    print(\"Issue to upload Analytics DataCube on AWS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload on Azure Cloud Storage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cloud_storage_azure.upload_directory_to_azure_blob_storage(zarr_path):\n",
    "    print(\"Analytics DataCube uploaded to Azure Blob Storage\")\n",
    "    print(f'Azure Blob url: {cloud_storage_azure.get_azure_blob_url_path(zarr_path)}')\n",
    "\n",
    "else:\n",
    "    print(\"Issue to upload Analytics DataCube on Azure Blob Storage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6Ô∏è‚É£ Display the results\n",
    "Visualize the results using matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time series for each indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# get list of available bands from the analytics datacube\n",
    "bands = list(analytics_datacube.data_vars.keys())\n",
    "\n",
    "for band in bands:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    indicator_ds = analytics_datacube.sel(band=band.upper())[band].sortby('time')\n",
    "\n",
    "    # Exclude NaN values to calculate the mean\n",
    "    masked_data_array = indicator_ds.where(~np.isnan(indicator_ds))\n",
    "\n",
    "    # index mean calculation\n",
    "    mean_index = masked_data_array.mean(dim=['x', 'y'])\n",
    "\n",
    "    # plot \n",
    "    mean_index.plot.line(x='time')\n",
    "\n",
    "    # labels & title\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel(band)\n",
    "    plt.title(f'{band.upper()} Time Series')\n",
    "    plt.grid()    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative index indicator values over the defined period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get list of available bands from the analytics datacube\n",
    "bands = list(analytics_datacube.data_vars.keys())\n",
    "\n",
    "for band in bands:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    indicator_ds = analytics_datacube.sel(band=band.upper())[band].sortby('time')\n",
    "\n",
    "    # Exclude NaN values to calculate the mean\n",
    "    masked_data_array = indicator_ds.where(~np.isnan(indicator_ds))\n",
    "\n",
    "    # index mean calculation\n",
    "    mean_index = masked_data_array.mean(dim=['x', 'y'])\n",
    "\n",
    "    # cumsum mean index calculation\n",
    "    cumul_index_ds = mean_index.cumsum(dim='time')\n",
    "\n",
    "    # plot \n",
    "    cumul_index_ds.plot.line(x='time')\n",
    "\n",
    "    # labels & title\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel(band)\n",
    "    plt.title(f'{band.upper()} cumulative mean values over time')\n",
    "    plt.grid()    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adcube",
   "language": "python",
   "name": "adcube"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
